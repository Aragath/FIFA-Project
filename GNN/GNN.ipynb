{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GNN\n",
    "Using hierachical pooling to reduce the graph until it's only one embedding\n",
    "- Hierachical pooling: reduce the nodes by distribute node to neighbor nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "from torch_geometric.nn import TransformerConv, TopKPooling \n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "torch.manual_seed(42)\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self, feature_size, model_params):\n",
    "        super(GNN, self).__init__()\n",
    "        embedding_size = model_params[\"model_embedding_size\"]\n",
    "        n_heads = model_params[\"model_attention_heads\"]\n",
    "        self.n_layers = model_params[\"model_layers\"]\n",
    "        dropout_rate = model_params[\"model_dropout_rate\"]\n",
    "        top_k_ratio = model_params[\"model_top_k_ratio\"]\n",
    "        self.top_k_every_n = model_params[\"model_top_k_every_n\"]\n",
    "        dense_neurons = model_params[\"model_dense_neurons\"]\n",
    "        edge_dim = model_params[\"model_edge_dim\"]\n",
    "\n",
    "        self.conv_layers = ModuleList([])\n",
    "        self.transf_layers = ModuleList([])\n",
    "        self.pooling_layers = ModuleList([])\n",
    "        self.bn_layers = ModuleList([])\n",
    "\n",
    "        # Transformation layer: transform original node features to embedding vector(size: embedding_size(defined in config.py))\n",
    "        self.conv1 = TransformerConv(feature_size, \n",
    "                                    embedding_size, \n",
    "                                    heads=n_heads, \n",
    "                                    dropout=dropout_rate,\n",
    "                                    edge_dim=edge_dim,\n",
    "                                    beta=True) \n",
    "\n",
    "        self.transf1 = Linear(embedding_size*n_heads, embedding_size)\n",
    "        self.bn1 = BatchNorm1d(embedding_size)\n",
    "\n",
    "        # Other layers: message passing and pooling\n",
    "        for i in range(self.n_layers):\n",
    "            self.conv_layers.append(TransformerConv(embedding_size, \n",
    "                                                    embedding_size, \n",
    "                                                    heads=n_heads, \n",
    "                                                    dropout=dropout_rate,\n",
    "                                                    edge_dim=edge_dim,\n",
    "                                                    beta=True))\n",
    "\n",
    "            # map conv_layer output size back to emgedding_size(embedding_size*n_heads -> embedding_size)\n",
    "            self.transf_layers.append(Linear(embedding_size*n_heads, embedding_size))\n",
    "            # Batch normalization\n",
    "            self.bn_layers.append(BatchNorm1d(embedding_size))\n",
    "            # Top-k pooling to reduce the size of the graph\n",
    "            if i % self.top_k_every_n == 0:\n",
    "                self.pooling_layers.append(TopKPooling(embedding_size, ratio=top_k_ratio))\n",
    "            \n",
    "\n",
    "        # Linear output layers: feed graph representation in & reduce until single value left\n",
    "        self.linear1 = Linear(embedding_size*2, dense_neurons)\n",
    "        self.linear2 = Linear(dense_neurons, int(dense_neurons/2))  \n",
    "        self.linear3 = Linear(int(dense_neurons/2), 1)  \n",
    "\n",
    "    def forward(self, x, edge_attr, edge_index, batch_index):\n",
    "        # Initial transformation\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = torch.relu(self.transf1(x))\n",
    "        x = self.bn1(x)\n",
    "\n",
    "        # Holds the intermediate graph representations\n",
    "        global_representation = []\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            x = self.conv_layers[i](x, edge_index, edge_attr)\n",
    "            x = torch.relu(self.transf_layers[i](x))\n",
    "            x = self.bn_layers[i](x)\n",
    "            # Always aggregate last layer\n",
    "            if i % self.top_k_every_n == 0 or i == self.n_layers:\n",
    "                x , edge_index, edge_attr, batch_index, _, _ = self.pooling_layers[int(i/self.top_k_every_n)](  x, \n",
    "                                                                                                                edge_index, \n",
    "                                                                                                                edge_attr, \n",
    "                                                                                                                batch_index)\n",
    "                # Add current representation\n",
    "                global_representation.append(torch.cat([gmp(x, batch_index), gap(x, batch_index)], dim=1))\n",
    "    \n",
    "        x = sum(global_representation)  ######\n",
    "\n",
    "        # Output block\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = F.dropout(x, p=0.8, training=self.training)\n",
    "        x = torch.relu(self.linear2(x))\n",
    "        x = F.dropout(x, p=0.8, training=self.training)\n",
    "        x = self.linear3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F \n",
    "# from torch.nn import Linear, BatchNorm1d, ModuleList\n",
    "# from torch_geometric.nn import TransformerConv, TopKPooling \n",
    "# from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "# torch.manual_seed(42)\n",
    "\n",
    "# class GNN(torch.nn.Module):\n",
    "#     def __init__(self, feature_size):\n",
    "#         super(GNN, self).__init__()\n",
    "#         num_classes = 2\n",
    "#         embedding_size = 1024\n",
    "\n",
    "#         # GNN layers\n",
    "#         self.conv1 = GATConv(feature_size, embedding_size, num_classes, heads=3, droupout=0.3)\n",
    "#         self.head_transform1 = Linear(embedding_size*3, embedding_size)\n",
    "#         self.pool1 = TopKPooling(embedding_size, ratio=0.8)\n",
    "#         self.conv2 = GATConv(embedding_size, embedding_size, heads=3, droupout=0.3)\n",
    "#         self.head_transform2 = Linear(embedding_size*3, embedding_size)\n",
    "#         self.pool2 = TopKPooling(embedding_size, ratio=0.5)\n",
    "#         self.conv3 = GATConv(embedding_size, embedding_size, heads=3, droupout=0.3)\n",
    "#         self.head_transform3 = Linear(embedding_size*3, embedding_size)\n",
    "#         self.pool3 = TopKPooling(embedding_size, ratio=0.2)\n",
    "\n",
    "#         # Linear layers\n",
    "#         self.linear1 = Linear(embedding_size*2, 1024) # 1024 dense neurons\n",
    "#         self.linear2 = Linear(1024, num_classes)   \n",
    "\n",
    "#     def forward(self, x, edge_attr, edge_index, batch_index):\n",
    "#         # First block\n",
    "#         x = self.conv1(x, edge_index)\n",
    "#         x = self.head_transform1(x)\n",
    "\n",
    "#         x, edge_index, edge_attr, batch_index, _, _ = self.pool1(x, \n",
    "#                                                                  edge_index,\n",
    "#                                                                  None,\n",
    "#                                                                  batch_index)\n",
    "#         x1 = torch.ccat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "\n",
    "#         # Second block\n",
    "#         x = self.conv2(x, edge_index)\n",
    "#         x = self.head_transform2(x)\n",
    "#         x, edge_index, edge_attr, batch_index, _, _ = self.pool2(x,\n",
    "#                                                                 edge_index,\n",
    "#                                                                 None,\n",
    "#                                                                 batch_index)\n",
    "#         x2 = torch.ccat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "\n",
    "#         # Third block\n",
    "#         x = self.conv3(x, edge_index)\n",
    "#         x = self.head_transform3(x)\n",
    "#         x, edge_index, edge_attr, batch_index, _, _ = self.pool3(x,\n",
    "#                                                                 edge_index,\n",
    "#                                                                 None,\n",
    "#                                                                 batch_index)\n",
    "#         x3 = torch.ccat([gmp(x, batch_index), gap(x, batch_index)], dim=1)\n",
    "\n",
    "#         # Concat pooled vectors\n",
    "#         x = x1 + x2 + x3\n",
    "\n",
    "#         # Output block\n",
    "#         x = self.linear1(x).relu()\n",
    "#         x = F.dropout(x, p=0.5, training=self.training)\n",
    "#         x = self.linear2(x)\n",
    "\n",
    "#         return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b075c2ba4667a0fecac182d8c53ecf752516f400485e55a5d8e8c5c7f6d3bc3b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
